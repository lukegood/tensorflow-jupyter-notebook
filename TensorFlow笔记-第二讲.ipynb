{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "代码、图片均来源于中国大学MOOC曹健老师《人工智能实践：TensorFlow笔记2》，地址：https://www.icourse163.org/learn/PKU-1002536002?tid=1452937471#/learn/announce ，部分代码在我练习过程中有修改。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([4 3 3 4], shape=(4,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([1, 2, 3, 4])\n",
    "b = tf.constant([4, 3, 2, 1])\n",
    "c = tf.where(tf.greater(a, b), a, b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "条件语句为真返回true，条件语句为假返回false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.417022004702574 [[7.20324493e-01 1.14374817e-04 3.02332573e-01 1.46755891e-01]\n",
      " [9.23385948e-02 1.86260211e-01 3.45560727e-01 3.96767474e-01]\n",
      " [5.38816734e-01 4.19194514e-01 6.85219500e-01 2.04452250e-01]]\n"
     ]
    }
   ],
   "source": [
    "rdm = np.random.RandomState(seed = 1)\n",
    "a = rdm.rand()\n",
    "b = rdm.rand(3, 4)\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.random.RandomState,rand(维度)返回一个指定维度的[0, 1)之间的随机数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [3 4 5]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1, 2, 3])\n",
    "b = np.array([3, 4, 5])\n",
    "c = np.vstack((a, b))\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vstack把两个数组按垂直方向叠加。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1]\n",
      " [2 2]\n",
      " [3 3]\n",
      " [4 4]\n",
      " [5 5]]\n",
      "[[2 3]\n",
      " [2 3]\n",
      " [2 3]\n",
      " [2 3]\n",
      " [2 3]]\n",
      "[[1 1]\n",
      " [2 2]\n",
      " [3 3]\n",
      " [4 4]\n",
      " [5 5]] [[2 3]\n",
      " [2 3]\n",
      " [2 3]\n",
      " [2 3]\n",
      " [2 3]]\n",
      "[[1 2]\n",
      " [1 3]\n",
      " [2 2]\n",
      " [2 3]\n",
      " [3 2]\n",
      " [3 3]\n",
      " [4 2]\n",
      " [4 3]\n",
      " [5 2]\n",
      " [5 3]]\n"
     ]
    }
   ],
   "source": [
    "x, y = np.mgrid[1:6:1, 2:4:1]\n",
    "print(x)\n",
    "print(y)\n",
    "grid = np.c_[x.ravel(), y.ravel()]\n",
    "print(x, y)\n",
    "print(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.mgrid返回若干组维度相同的等差数组，起始值，结束值，步长，左闭右开区间。x.ravel将x变为一维数组，np.c_[]使返回的间隔数值点配对。\n",
    "感觉这里mooc里解释的有问题。mgrid应该是返回多维结构，常见的如2D图形，3D图形。第一个参数表示k维，它朝右扩展；第二个参数表示b维，它朝下扩展。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 0 epoch, w is 4.000000, loss is 36.000000, lr is 0.200000\n",
      "after 1 epoch, w is 3.208000, loss is 25.000000, lr is 0.198000\n",
      "after 2 epoch, w is 2.579168, loss is 17.707266, lr is 0.196020\n",
      "after 3 epoch, w is 2.078655, loss is 12.810442, lr is 0.194060\n",
      "after 4 epoch, w is 1.679305, loss is 9.478117, lr is 0.192119\n",
      "after 5 epoch, w is 1.359905, loss is 7.178678, lr is 0.190198\n",
      "after 6 epoch, w is 1.103840, loss is 5.569150, lr is 0.188296\n",
      "after 7 epoch, w is 0.898070, loss is 4.426144, lr is 0.186413\n",
      "after 8 epoch, w is 0.732332, loss is 3.602670, lr is 0.184549\n",
      "after 9 epoch, w is 0.598532, loss is 3.000975, lr is 0.182703\n",
      "after 10 epoch, w is 0.490272, loss is 2.555306, lr is 0.180876\n",
      "after 11 epoch, w is 0.402480, loss is 2.220911, lr is 0.179068\n",
      "after 12 epoch, w is 0.331130, loss is 1.966951, lr is 0.177277\n",
      "after 13 epoch, w is 0.273015, loss is 1.771906, lr is 0.175504\n",
      "after 14 epoch, w is 0.225579, loss is 1.620567, lr is 0.173749\n",
      "after 15 epoch, w is 0.186777, loss is 1.502044, lr is 0.172012\n",
      "after 16 epoch, w is 0.154970, loss is 1.408439, lr is 0.170292\n",
      "after 17 epoch, w is 0.128844, loss is 1.333956, lr is 0.168589\n",
      "after 18 epoch, w is 0.107340, loss is 1.274289, lr is 0.166903\n",
      "after 19 epoch, w is 0.089603, loss is 1.226201, lr is 0.165234\n",
      "after 20 epoch, w is 0.074946, loss is 1.187236, lr is 0.163581\n",
      "after 21 epoch, w is 0.062809, loss is 1.155509, lr is 0.161946\n",
      "after 22 epoch, w is 0.052739, loss is 1.129563, lr is 0.160326\n",
      "after 23 epoch, w is 0.044368, loss is 1.108259, lr is 0.158723\n",
      "after 24 epoch, w is 0.037396, loss is 1.090705, lr is 0.157136\n",
      "after 25 epoch, w is 0.031579, loss is 1.076191, lr is 0.155564\n",
      "after 26 epoch, w is 0.026715, loss is 1.064155, lr is 0.154009\n",
      "after 27 epoch, w is 0.022642, loss is 1.054145, lr is 0.152469\n",
      "after 28 epoch, w is 0.019224, loss is 1.045797, lr is 0.150944\n",
      "after 29 epoch, w is 0.016352, loss is 1.038818, lr is 0.149434\n",
      "after 30 epoch, w is 0.013933, loss is 1.032971, lr is 0.147940\n",
      "after 31 epoch, w is 0.011892, loss is 1.028059, lr is 0.146461\n",
      "after 32 epoch, w is 0.010168, loss is 1.023925, lr is 0.144996\n",
      "after 33 epoch, w is 0.008708, loss is 1.020439, lr is 0.143546\n",
      "after 34 epoch, w is 0.007471, loss is 1.017492, lr is 0.142111\n",
      "after 35 epoch, w is 0.006420, loss is 1.014997, lr is 0.140690\n",
      "after 36 epoch, w is 0.005525, loss is 1.012880, lr is 0.139283\n",
      "after 37 epoch, w is 0.004764, loss is 1.011081, lr is 0.137890\n",
      "after 38 epoch, w is 0.004113, loss is 1.009550, lr is 0.136511\n",
      "after 39 epoch, w is 0.003557, loss is 1.008244, lr is 0.135146\n"
     ]
    }
   ],
   "source": [
    "w = tf.Variable(tf.constant(5, dtype = tf.float32))\n",
    "LR_BASE = 0.2\n",
    "LR_DECAY = 0.99\n",
    "LR_STEP = 1\n",
    "epoch = 40\n",
    "\n",
    "for epoch in range(epoch):\n",
    "    lr = LR_BASE * LR_DECAY ** (epoch / LR_STEP)\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = tf.square(w + 1)\n",
    "    grads = tape.gradient(loss, w)\n",
    "    w.assign_sub(lr * w)\n",
    "    print(\"after %s epoch, w is %f, loss is %f, lr is %f\" % (epoch, w.numpy(), loss, lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.wangliguang.cn/wp-content/uploads/2020/03/批注-2020-03-17-162014.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.34875482]\n",
      " [-1.9341799 ]]\n",
      "[[ 1.3077168 ]\n",
      " [-0.44903868]]\n",
      "[[1.535863  ]\n",
      " [0.13267002]]\n",
      "[[1.5353235]\n",
      " [0.3959133]]\n",
      "[[1.4718056]\n",
      " [0.5399524]]\n",
      "[[1.3985068]\n",
      " [0.6339418]]\n",
      "[[1.3312589]\n",
      " [0.7029188]]\n",
      "[[1.2737054 ]\n",
      " [0.75676817]]\n",
      "[[1.225691  ]\n",
      " [0.80002147]]\n",
      "[[1.1860368]\n",
      " [0.8351922]]\n",
      "[[1.1534184 ]\n",
      " [0.86393774]]\n",
      "[[1.1266327]\n",
      " [0.8874816]]\n",
      "[[1.1046516]\n",
      " [0.9067821]]\n",
      "[[1.086618 ]\n",
      " [0.9226095]]\n",
      "[[1.071824 ]\n",
      " [0.9355909]]\n",
      "[[1.059689 ]\n",
      " [0.9462385]]\n",
      "[[1.049735  ]\n",
      " [0.95497227]]\n",
      "[[1.0415702 ]\n",
      " [0.96213627]]\n",
      "[[1.0348728 ]\n",
      " [0.96801233]]\n",
      "[[1.0293794 ]\n",
      " [0.97283214]]\n",
      "[[1.0248733]\n",
      " [0.9767857]]\n",
      "[[1.0211773]\n",
      " [0.9800288]]\n",
      "[[1.0181456]\n",
      " [0.9826888]]\n",
      "[[1.0156586]\n",
      " [0.9848706]]\n",
      "[[1.0136193]\n",
      " [0.9866603]]\n",
      "[[1.0119456 ]\n",
      " [0.98812854]]\n",
      "[[1.010574 ]\n",
      " [0.9893326]]\n",
      "[[1.0094488]\n",
      " [0.9903197]]\n",
      "[[1.0085258 ]\n",
      " [0.99113035]]\n",
      "[[1.007766]\n",
      " [0.991794]]\n"
     ]
    }
   ],
   "source": [
    "SEED = 23455\n",
    "\n",
    "rdm = np.random.RandomState(seed = SEED)\n",
    "x = rdm.rand(32, 2)\n",
    "y_ = [[x1 + x2 + (rdm.rand()/10-0.05)] for (x1, x2) in x]\n",
    "x = tf.cast(x, dtype = tf.float32)\n",
    "\n",
    "w1 = tf.Variable(tf.random.normal([2, 1], stddev = 1, seed = 1))\n",
    "\n",
    "epoch = 15000\n",
    "lr = 0.002\n",
    "\n",
    "for epoch in range(epoch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y = tf.matmul(x, w1)\n",
    "        loss = tf.reduce_mean(tf.square(y_ - y))\n",
    "    grads = tape.gradient(loss, w1)\n",
    "    w1.assign_sub(lr * grads)\n",
    "    if epoch % 500 == 0:\n",
    "        print(w1.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[1.68795487e-04 1.03475622e-03 6.58839038e-02 2.58349207e+00\n",
      " 5.49852354e-02], shape=(5,), dtype=float64) tf.Tensor(\n",
      "[1.68795487e-04 1.03475622e-03 6.58839038e-02 2.58349207e+00\n",
      " 5.49852354e-02], shape=(5,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "y_ = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 0, 0], [0, 1, 0]])\n",
    "y = np.array([[12, 3, 2], [3, 10, 1], [1, 2, 5], [4, 6.5, 1.2], [3, 6, 1]])\n",
    "y_pro = tf.nn.softmax(y)\n",
    "loss1 = tf.losses.categorical_crossentropy(y_, y_pro)\n",
    "loss2 = tf.nn.softmax_cross_entropy_with_logits(y_, y)\n",
    "print(loss1, loss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[1.68795487e-04 1.03475622e-03 6.58839038e-02 2.58349207e+00\n",
      " 5.49852354e-02], shape=(5,), dtype=float64) tf.Tensor(\n",
      "[1.68795487e-04 1.03475622e-03 6.58839038e-02 2.58349207e+00\n",
      " 5.49852354e-02], shape=(5,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "y_ = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 0, 0], [0, 1, 0]])\n",
    "y = np.array([[12, 3, 2], [3, 10, 1], [1, 2, 5], [4, 6.5, 1.2], [3, 6, 1]])\n",
    "y_pro = tf.nn.softmax(y)\n",
    "loss1 = tf.losses.categorical_crossentropy(y_, y_pro)\n",
    "loss2 = tf.nn.softmax_cross_entropy_with_logits(y_, y)\n",
    "print(loss1, loss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-363ffe4f756f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0my_pro\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mloss1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategorical_crossentopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pro\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mloss2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax_cross_entropy_with_logits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pro\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "y_ = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 0, 0], [0, 1, 0]])\n",
    "y = np.array([[12, 3, 2], [3, 10, 1], [1, 2, 5], [4, 6.5, 1.2], [3, 6, 1]])\n",
    "y_pro = tf.nn.softmax(y)\n",
    "loss1 = tf.losses.categorical_crossentopy(y_, y_pro)\n",
    "loss2 = tf.nn.softmax_cross_entropy_with_logits(y_, y_pro)\n",
    "print(loss1, loss2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
